[
    {
        "speaker": "SPEAKER_01",
        "text": "복잡한 테이블 같은 경우는 인식률이 좀 떨어지는 문제들이 있었어요. 그래서 모델의 워크플로우나 모델의 성능은 좋은데 데이터 수집과 전처리 과정에서 품질에 문제가 생기면 결국은 틀린 답을 출력할 수 있는 가능성이 높아지는 한계점들을 좀 도출이 되었습니다. 그래서 저희가 12월에는 그런 부분들을 개선하기 위해서 다큐멘트 인테리전스, 문서를 수집하고 전처리하는 부분들을 기능을 고도화하는 부분들을 탑재하는 걸 진행하고 있고요. 마찬가지로 복도에 나가시면 에자이소다가 부스를 통해서 소개를 드리는 기능이 바로 ETL4 LLM이라고 하는 에자이소다 같은 경우는 AI OCR 기반으로 이미지 PDF나 문서 안에 있는 이미지 안에서도 캐릭터를 투출해서 방금 좀 말씀드렸던 문서를 수집하고 전처리하는 과정에서 성능을 높이는데 굉장히 도움을 둘 수 있는 솔루션으로 함께 소개를 드릴 수 있을 것 같습니다."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "이게 이제 2024년 12월에 제노스 1차..."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "달라질지에 대해서 전망을 좀 해봤습니다. 사실 이 전망은 만체 컴퍼니가 바라보는 뷰이기 때문에 기술의 변화의 속도라든가 방향이라든가 또는 시장에서 좀"
    },
    {
        "speaker": "SPEAKER_01",
        "text": "생길 수 있을 것 같아요. 잘 아시는 것처럼 생성형 AI의 기술 변화 속도가 너무 빠르잖아요. 그래서 1년 후에 기술을 정확하게 예측하는 것 자체는 크게 예측하기 너무 힘든 일인 것 같고요. 중요한 거는 어느 방향으로 좀 기술이 진화할 건지 좀 그러한 기술들을 내가 담당하고 있는 업무, 비즈니스에는 어떻게 좀 적용할지에 대한 관점을 갖추는 게 훨씬 더 중요하다고 생각이 됩니다. 저희가 제노스 1.4 버전을 25년 1분기에 좀 업데이트를 하려고 계획을 하고 있는데요. 그때 업데이트되는 기능에 대한 걸 크게 좀 3가지 방향으로 잡아봤습니다. 첫 번째는 시퀀셜한 에이전트. 앞서 이제 저희가 태스크플로우 빌더를 통해서 연속적인 태스크를 수행할 수 있는 부분들을 편집하고 시나리오를 편집하고 옵션을 제어할 수 있는 기능을 탑재했다고 좀 말씀을 드렸는데요. 이 부분은 사람이 관여하는 부분이 너무 높아요. 어느 부분에서 분기할지, 분기한 다음에 AR 빌딩 어떤 액션을 처리할지를 사람이 좀 한 땀 한 땀 정리해야 되는 비중이 굉장히 높은데요. 내년 1분기에 런칭할 시퀀셜 에이전트 같은 경우는 리진행하는 부분에 있어서 LLM 모델을 판단해서 도움을 받습니다. 그래서 분기가 된다거나 다음 액션을 수행할 때 어떤 에이전트와 어떤 경로로 가는 것들이 더 적절한지를 LLM 모델의 리진행 기능을 통해서 도움을 받는 형태로 기술이 진화할 거라고 예상을 하고 있습니다. 두 번째는 멀티 에이전트인데요. 사실 이제 폐쇄화 환경에서 SLM, 상대적으로 파라미터가 작은 모델들을 도입하는 과정에서 태스크 스페시픽한, 그래서 특정 태스크를 잘 수행하는 모델 중심으로 도입을 했었는데요. 앞서 저희가 AI 업무비서가 다양한 업무를 동시에 잘하는 기능으로 도입에 대한 사례를 말씀드렸는데 멀티 에이전트는 뒤에 좀 더 말씀을 드리겠지만"
    },
    {
        "speaker": "SPEAKER_01",
        "text": "여러 에이전트가 약간 협업하는"
    },
    {
        "speaker": "SPEAKER_01",
        "text": "있어서 이 문제를 풀 때 ABC 워커가 한번 같이 문제를 풀어봐라는 방식으로 다양한 에이전트들이 협업을 통해서 더 좋은 결과를 도출할 수 있는 방식의 워크플로우가 진화가 예상이 되고 있습니다. 세번째는 저희가 실제 고객사에서 내년 2분기까지 저희가 도입을 해야되는 멀티모달 LLM, 지금 텍스트레이스의 랭키지 모델 중심으로 저희가 도입을 하고 있는데 이미지와 텍스트와 같은 다양한 인풋과 출력을 제어할 수 있는 멀티모달 LLM으로 고도화가 될 것 같고요. 이 부분에 이제 25년 1분기에 저희가 1.4 버전으로 업데이트하면서 조금 더 추가될 기능입니다. 맨 오른쪽에 있는 25년 4분기라고 제가 예상을 했는데요. 사실 제 마음속에는 2분기까지 됐으면 좋겠는데 여기 또 저희 직원들도 있고 개발자분들도 있어서 너무 압박을 드리는 것 같아서 4로 좀 숫자를 바꿨는데요."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "발전할지에 대한 것을 조금 더 정리해보자면"
    },
    {
        "speaker": "SPEAKER_01",
        "text": "사실 가로축이 조금 다 이어져요. 그러니까 테스크플로우와 관련돼서 사람이 한 땅 한 땅 순서를 정하던 것을 리지닝하는 것을 판단하는 것을 이제는 오토노머스 AI 에이전트라는 것은 골만 설정하면 어떤 테스크를 수행해야 되는지를 AI가 스스로 에이전트를 만들어가는 오토노머스 AI 에이전트가 상용화 된 단계로 25년 말까지는 기술이 좀 발전할 거라고 예상하고 있고요. 두 번째는 이제 개인화된 에이전트, 지금은 누가 물어보더라도 똑같은 대답을 하고 있는데 나의 이력과 어떤 프리퍼런스를 좀 고려해서 컨텍스트에 맞는 적절한 대답을 해주는 개인화 에이전트로 진화할 거라고 생각하고 있습니다. 세 번째는 지금 이제 도입하고 있는 대부분의 생성형 AI 들이 채팅창 안에서 텍스트로 요청하면 텍스트로 대답하는 형태의 워크플로우들을 좀 가지고 있는데요. 25년 말이 되면 훨씬 더 액셔너블한 AI가 멀티모델과 함께 내가 컴퓨터에 있는 어떤 모니터를 보는 것처럼 AI도 화면을 캡처하면서 채팅창 안에 있는 것에서만 제어하는 게 아니라 다른 2종의 소프트웨어도 제어하고 레버시에 있는 시스템에 대한 제어를 통해서 훨씬 더 액셔너블한 에이전트를 만들 수 있는 걸로 진화할 거라고 예상하고 있습니다. 그래서 오늘 좀 말씀드린 어떤 9개의 카드 이게 이제 저희가 예상하는 현재에서 25년까지 생성형 AI 기술이 어떻게 진화할 건지 그것들을 좀 세 가지로 나눠보자면 시퀀셜한 에이전트를 훨씬 더 자동화된 방식으로 만들어가는 부분, 개인화된 방식으로 답변이 출력되는 부분, 그 다음에 훨씬 더 액셔너블한 에이전트로 기술이 좀 고도화될 거다라고 방향을 정리해 볼 수 있을 것 같습니다. 9개의 카드에 대해서 하나하나 좀 간단하게 설명을 드릴 텐데요. 첫 번째는 테스크플로우 빌더 같은 경우는 마지막 세션에서 제노스 1.3에 대한 업데이트에 대한 부분들을 설명드리면서 앞서 말씀드렸던 것처럼 싱글턴에 대한 액션만 컨트롤하는 게 아니라 분기가 필요하고 단계가 필요하고 추가적인 대화를 진행하려면 슬롯을 필링해야 되는 부분들에 대한 옵션을 설정할 수 있는 것들을 메뉴상으로 구현되어 있습니다. 그래서 그 부분에 대해서는 앞서 말씀드렸던 것처럼 마지막 세션에서 조금 더 자세히 시연을 드리도록 하겠습니다."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "두번째는 나만의 GPT 인데요. 저희가 앞서 좀 설명드렸던 것처럼 중부발전에 저희가 11월에 페세버 환경에서 QN-72 모델을 가지고 라마-405B와 QN-72 두가지 모델을 좀 사용을 했는데요. 앞서 말씀드렸던 것처럼 이전에 AI는 굉장히 테스트 스페시픽한 특정 비즈니스에 적절하게 파인튜닝을 많이 하고 거기에 좀 오버피팅 되는 방식의 좀 에이전트를 만들었었는데 사실 앞서 처음에 강조드렸던 것처럼 우리가 오피스나 엑셀에 익숙해지듯이 업무 담당자들이 GPT에 훨씬 더 익숙해져야 돼요. 이제 망이 좀 분리되어 있어서 GPT를 쓸 수 없는 환경에서 내가 문서를 요약한다든가 번역한다든가 아니면 보고서에 초안을 생성한다든가 제가 오늘 PPT 자료 준비하면서도 오른쪽에 있는 디스크립션을 작성할 때 실제 저희가 오픈한 나만의 GPT를 가지고 초안을 좀 생성해달라고 하는거, 시퀀셜 에이전트에 대한 정의를 좀 해줘, 멀티 에이전트는 어떻게 설명하는게 좋을까 라는 것들을 저희가 서비스하고 있는 나만의 GPT에 물어보고 그것들을 가져와서 굉장히 좀 편하게 좀 자료를 만드는 데 실제 좀 사용을 했었습니다."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "저희가 전단지, 너무 광고 맞나요? 전단지도 좀 같이 나눠드렸는데요. 1억에 도입하는 생소형 AI 패키지, HBAC 서버 2장까지 함께 드립니다."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "GPU 두 장이 1억이 넘잖아요. 1억에 준다. 사실 작은 글씨도 잘 보셔야 돼요. 그래서 이게 그냥 1억에 다 드리는 건 아니고요. 연간 구독형으로 1억에 소프트웨어와 하드웨어를 구독형 방식으로 제공하는 것을 좀 오퍼링을 해드리려고 하고 있습니다. 많은 기업들이 작은 기능 하나만 써보려고 해도 GPU가 워낙 비싸니까 인프라에 대한 부담이 많이 좀 있으실 것 같아요. 좀 그런 부분들을 좀 어떻게 해결할 수 있을지를 좀 고민하는 과정에서 저희가 좀 생각해본 좀 패키지이고요. 이 부분도 말씀드렸던 것처럼 좀 밖에 부스에서 같이 좀 체험도 해보시고 구체적인 상담도 받아보시면 좋을 것 같습니다."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "세 번째는 이제 다큐멘트 인텔리전스 관련한 건데요. 이거는 이제 말씀드렸던 것처럼 저희가 1.2 버전에서도 원래 제공하던 기능이에요. 문서의 레이아웃별로 뭐 수집하고 전처리하고 레이아웃별로 최적화된 임배등 하는 거는 적용했는데요. 앞서 말씀드렸던 인식하는 과정에서 이미지에 대한 부분에 유실이 생긴다던가 복잡한 테이블에 대한 것들을 열을 틀리면 틀린 답을 이렇게 출력하게 되잖아요. 그런 부분들을 보완하는 대안이 필요하다. 저희가 미래세 집권과 함께 고민하고 있는 포인트고 그 부분을 해결하기 위해서 앞서 좀 소개드렸던 것처럼 AI OCR과 다큐멘트 인텔리전스와 관련된 전문적인 기술을 쌓고 있는 에자열소다와 함께 ETL4 LLM이라고 하는 앞서 저희가 한계라고 했던 대긴데는데 잘 안되는 그래서 정확도가 떨어지는 부분들을 이런 다큐멘트 인텔리전스 솔루션을 보완해서 문서 전처리에 대한 정확도를 높이는 방식으로 모델의 성능, 서비스의 성능을 높여볼 수 있을 것 같습니다."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "이게 좀 1.3에서 제공하는 기능을 소개 드렸고요. 그럼 이제 내년 1분기에 저희가 도입하려고 하는 1.4버전의 세 가지의 기능에 대해서 간단하게 설명을 드릴텐데요. 사실 이제 저희가 발표 세션 시간이 좀 짧다 보니까 하나하나 기술에 대해서 아주 디테일한 설명을 드리기는 조금 어려울 것 같고 개념적으로만 설명을 드리면 앞서 말씀드렸던 것처럼 이전에 예를 들면 레그라든가 한번 질의하면 한번 답변하는 플로우는 이미 랭채널 기반으로 쉽게 만들 수가 있어요. 그런데 태스크를 완결하려면 단계가 필요한 거죠. 그런 시퀀셜한 부분들을 어떻게 좀 설정할 수 있는지가 좀 중요한데요. 저희 태스크 플로우에서도 그런 기능이 됩니다. 그런데 말씀드렸던 것처럼 그러면 적금을 가입하려면 기간을 물어보고 기간 다음에는 금액을 물어보고 이런 걸 다 설정해줘야 돼요. 그 작업이 굉장히 좀 지난한 작업이기 때문에 시퀀셜 에이전트는 이게 다이렉티드 사이클링 그래프라고 하는 랭 그래프 기반으로 이거를 사람이 한 땀 한 땀 정하지 않아도 방향이 있어요. 내가 태스크로 완결하는 고루 완결하는 방향이 있고 이 단계에서 어떤 옵션에 대한 어떤 조건에 대한 것들을 실행해야 되는지를 LLM 모드를 훨씬 더 리즈닝하는 방식으로 고도화되는 것들을 볼 수가 있습니다. 그래서 오른쪽에 보시면 한 세 가지의 구성 요소가 좀 있는데요. 하나는 조건에 대한 노드, 분기에 대한 것을 설정하는 부분이 있고요. 그 다음에 두 번째는 스테이터스를 트래킹할 수 있는 부분들 아까 말씀드렸던 기간과 금액은 고객이 한 번 얘기하면 24개월 30만원은 대화가 계속 진행되더라도 상태를 좀 들고 있는 기능들 그 다음에 루프 노드라는 걸 통해서 내가 원하는 골에 달성할 수 있는 형태를 반복적으로 실행해서 원하는 결과에 도달할 수 있는 개념의 에이전트 플로우라고 보시면 좋을 것 같습니다. 두 번째 멀티 에이전트는 앞서 좀 설명드렸던 것처럼 지금 이제 하나의 모델이 하나의 태스크를 수행하는데 워크플로우 구성 자체를 왼쪽에 보시는 것처럼 하나의 슈퍼마이저가 있습니다. 모델의 관리자가 있고 그 다음에 다양한 워커들이 있습니다."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "테스크를 잘하는 워커들을 모아놓은 다음에 지금은 저희 모델의 초이스"
    },
    {
        "speaker": "SPEAKER_01",
        "text": "IP가 더 좋은지를 비교해본 다음에 그중에 제일 좋은 모델 하나로 이제 서비스를 구현하는 방식을 채택하고 있는데요. 그런 방식이 아니라 워커 자체를 좀 다양하게 놓는 거죠. 특정 검색은 A 모델이 잘하고 요약은 B 모델이 잘하고 리즈닝은 C 모델이 잘하면 그런 모델들을 같이 좀 저희가 구성을 한 다음에 협업하는 방식으로 답을 도출하게 된다면 훨씬 더 요즘 에이전트가 해결할 수 있는 커버레이지나 수준이 높아질 수 있을 것 같고요. 그것들을 구성하고 있는 핵심적인 구성요소가 슈퍼바이저 부분과 워커라는 것들로 구성이 되어 있습니다."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "세번째는 이제 멀티모달 LLM 인데요. 그래서 이 부분은 저희가 이미 R&D도 진행을 하고 있고 그래서 인풋과 아웃풋의 텍스트로만 진행이 되는게 아니라 이미지와 텍스트나 또는 음성이나 영상들도 같이 인풋으로 들어가고 출력으로 제어하는 도구들로 연결해 볼 수 있을 것 같구요. 그래서 앞서 저희가 다큐멘트 인텔리전스도 OCR이라는 기능을 통해서 이미지에 대한 인식의 정확도를 높이는 것을 해결할 수 있는 방법 중에 하나인데요. 사실 멀티모달 LLM이 들어오면 OCR이 아니더라도 문서 전체에 대한 레이아웃을 멀티모달과 텍스트에 대한 것을 같이 고려해서 훨씬 더 인식에 대한 정확도나 출력에 대해서도 훨씬 더 저희가 활용할 수 있는 여지들이 넓어질 것 같구요. 다양한 영역에서 멀티모달에 대한 수요가 늘어나고 있습니다. 아직까지 상용화에 대한 레퍼런스가 많지 않은데 저희가 내년 1분기에 제노스 1.4를 업데이트하면서 지금의 모델이 LLM 모델과 엠베딩 모델 두가지로 구분이 되어있는데 멀티모달에 대한 메뉴를 추가해서 다양한 업플로우에 멀티모달까지 학습하고 서빙할 수 있는 기능을 추가할 예정입니다."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "세번째는 이제 저희가 25년 말까지 하지만 제 마음속에는 내년 2분기까지 됐으면 좋겠는건데요. 3가지로 좀 제가 말씀을 드렸는데, 첫번째는 앞서 말씀드렸던 것처럼 시퀀스에 대한 것을 설정하는 것 또는 에이전트를 어떤 기능이나 분기에 대한 것을 설정하는 것을 사람에 의존하는게 되게 힘든 일이에요. 한 땀 한 땀 누드와 분기와 조건과 슬롯을 설정하는게 되게 어려운 일이기 때문에 저희가 고를 설정합니다. 우리는 AI된 것처럼 너넨 접근가입을 완결하는 에이전트야 라는 고를 설정하면 그 접근가입을 완결하기 위해서 어떤 테스트를 수행해야 되는지"
    },
    {
        "speaker": "SPEAKER_01",
        "text": "액션 툴들을 이용해야 되는지를 AI가 리즈닝하고 스스로 실험해보고 좋은 결과들을 나타내는 것들을 채택함으로써 에이전트를 완성하는 과정이라고 보시면 좋을 것 같고요. 이건 슈퍼 AGI에서 AGI 빌더라고 하는 제가 말씀드렸던 테스크를 설정하고 모델이 어떤 테스크의, 아, 고를 설정하고 모델이 이제 수행할 수 있는 테스크에 대한 후보 테스크를 리스터하고 각각의 테스크를 수행하기 위해서는 왼쪽에 보시는 것처럼 다양한 툴이나 액션이 필요해요. 그런 것들을 트라이해보고 결과가 좋으면 채택하고 아니면 다른 액션 툴을 좀 이용해 볼 수 있는 것들이 이미 이제 저작 도구까지 나와 있습니다. 다만 이제 AGI라고 얘기되는 Autonomous AI 에이전트가 상용화 단계에서는 아직 크게 좀 레퍼런스가 많지는 않아요. 그래서 제가 25년 말까지로 좀 예측을 하고 그 다음에 이 방향 자체가 어, Autonomous AI 에이전트로 만든 개별 버티컬한 에이전트가 더 확산이 될지 아니면 Autonomous AI 에이전트로 만드는 빌더가 더 기업의 니지가 있을지는 기술의 변화랑 그 다음 비즈니스 상황에 따라 좀 달라질 수 있을 것 같습니다."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "두번째, 아 이게 이제 아까 우리가 우리은행 하면서 왼쪽에 보시는 게"
    },
    {
        "speaker": "SPEAKER_01",
        "text": "6개월 동안 한 땀 한 땀 우리 은행 현업분들과 함께 접근 가입을 하려면 어떤 시나리오로 가입을 해야되는지 보기만 해도 눈알이 빠질 것 같고 되게 힘들어 보이죠. 이런 작업을 통해서 저희가 AI 뱅커를 런칭했는데요. 오른쪽에 보시는 것처럼 앞으로 이제 오토노먼스 AI 에이전트 같은 경우는 너의 목표는 접근을 가입하는 거야라는 것만 입력하면 접근을 가입하려면 고객의 의도도 이해해야 되고 상품도 추천해줘야 되고 만기의 지급액도 계산해줘야 되고 이런 태스크들을 리스트업 한 다음에 사실 LLM모델이 만기지급액을 계산하는 건 못하잖아요. 그러면 만기지급액을 계산할 수 있는 태스크매니저를 호출해서 그 액션을 호출한 다음에 숫자를 받아서 답변을 제노해주는 것들을 자동적으로 설계하는 것들이 오토노먼스 AI 에이전트 단계에서는 구현이 될 수 있을 것 같습니다."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "두번째는 개인 아이전트인데요. 개인 아이전트는 GPT 쓰시면 화면이 작아서 안 보이실 것 같긴 한데 메모리 라는 기능이 있어요. GPT가 최근에 메모리에 대한 설정을 활성화 할 수도 있고 비활성화 할 수도 있고 메모리 기능을 활성화 하면 내가 이전에 어떤 질문을 했는지 어떤 걸 더 선호하는지 어떤 답변에 더 Thumbs up down을 했는지에 대한 거를 다 기록을 해놔요. 그리고 새로운 질문할 때 그러한 이력과 선호에 맞춰서 맞춤형으로 답변하는 것들을 구현을 하고 있습니다. 그런 부분들이"
    },
    {
        "speaker": "SPEAKER_01",
        "text": "개인화를 하기 위한 어떤 그 시작점이 좀 될 것 같고요. 그래서 첫 번째는 이력에 대한 로그에 대한 것들을 잘 쌓는 게 좀 필요할 것 같아요. 그래서 이전에 대화했던 것들을 복원하고 히스토리에 진입할 수 있고 개개인별로 로그를 잘 쌓은 다음에 어떻게 좀 패턴이나 유형에 맞게 좀 오퍼링 할지에 대한 좀 고민들이 필요한데요. 저희가 좀 고민하고 있는 것 중 하나는 오른쪽 아래 4번에 MOE라는 방식으로 사실 이제 개인화를 하려면 모델을 뭔가 조종해야 되잖아요. 근데 뭐 70B 모델을 개인별로 파인트닝 하는 거는 자원의 효율성이나 이런 게 답이 안 나와서 구현이 좀 어려울 수 있습니다. 그래서 저희가 좀 아이디어를 착안한 거는 MOE라고 해서 여러 이제 엑스퍼트에 해당하는 그러니까 로라를 되게 잘게 쪼개는 거예요. 로라 같은 경우는 특정 태스크를 잘하기 위해서 일부 파라미터에 대한 파인트닝을 하는 방식인데 그거를 훨씬 더 작은 단위로 나누고 개인에게 최적화된 답변하기 위한 개인화된 로라 학습을 통해서 한번 구현해보는 걸 아이디어 레벨에서 좀 고민을 해보고 있습니다. 그래서 말씀드렸던 것처럼 25년 말까지니까 저희가 좀 1년이라는 시간 동안 당연히 좀 히스토리에 대한 축적 거기에 기반해서 좀 오퍼링하는 거는 진행할 건데요. 개인의 어떤 선호를 어떻게 판단할 거냐 거기에 맞춰서 맞춤형으로 답변을 어떻게 생성할 거냐라는 부분에 있어서는 방금 좀 소개드렸던 기술 방식을 좀 고민해보고 있습니다. 세 번째가 이제 액션노블 AI인데요. MS 코파일럿에서는 MS 오피스 내부에 있는 건 이미 액션노블을 하고 있어요. 그래서 이메일 아웃룩이라든가 PPT라든가 이런 부분들에 대한 테스크에 대한 플로우를 연결해서 채팅창 안에서만 진행하는 게 아니라 내가 일정에 등록하고 일정에 되면 메일을 보내고 회의를 하면 회의룩에 대한 걸 초안을 작성한 다음에 공유하고 이런 거는 이제 오피스 안에서는 다 돼요. 그게 이제 어떤 액션노블 AI의 시발점이라고 생각을 하고 있고요. 최근 액션노블 AI에 관련된 가장 적극적인 행보를 보이고 있는 회사 중에 하나가 엔트로픽 AI인데요. 엔트로픽 AI는 클로드 모델을 활용해서 컴퓨터 유즈라고 하는 기능을 새롭게 소개를 하고 있습니다. 아래에 영상에 대한 링크가 있어서 보시면 좋을 것 같은데 얘는 이제 MS 코파일럿처럼 자산 솔루션만 제어하는 게 아니고요. 컴퓨터 화면을 멀티모드하고 스냅샷으로 계속 찍어요. 내가 사용자가 보고 있는 컴퓨터 화면을 계속 스냅샷으로 캡쳐를 한 다음에 이게 어떤 거냐면"
    },
    {
        "speaker": "SPEAKER_01",
        "text": "물품에 대한 주문할 때 협력사 벤더의 정보를 조회한 다음에 해당 정보를 입력창에 자동으로 AI가 넣는 과정들을 좀 보여주고 있는데요. 이런 것들이 가능하려면 아까 말씀드렸던 기본적으로 멀티모델과 같이 연계가 되고 예전에 좀 RPA가 했던 것처럼 이종의 소프트웨어를 제어할 수 있는 기술들이 같이 좀 고도화가 되면서 이게 좀 결합이 되면 말씀드렸던 것처럼 질문에 대답만 하는 게 아니라 내가 필요로 하는 업무들을 이종의 소프트웨어든 내가 보고 있는 컴퓨터 화면이든 내부에 있는 레버싱 시스템에 대한 제어까지 연계해서 훨씬 더 액션을 완결할 수 있는 영역이 넓어질 것 같습니다."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "네 제가 짧은 시간안에 빠르게 좀 설명을 드렸는데요. 첫번째 세션을 좀 마무리를 해보도록 하겠습니다. 마인젠컴퍼니가 지난 2년동안 굉장히 다양한 고객사들과 생소형 AI에 대한 상용화에 대한 노력들과 경험들을 쌓아오고 있는데요. 그 관점에서 몇가지 정도로 좀 방향들을 요약을 해보자면 첫번째는 앞서 말씀드렸던 것처럼 회세만 이지만 기술의 변화가 너무 빨라요. 그래서 외부에서 빠르게 변화하고 있는 기술들을 기업 내부로 유연하게 반입하고 활용할 수 있는 체계를 마련하는게 굉장히 좀 시급하게 좀 필요하다고 생각합니다. 특히 금융사 같은 경우는 망불이 예외조치나 이런 규제 완화의 흐름이 있긴 하지만 규제가 완화되는 속도보다 기술의 변화되는 속도가 훨씬 더 빠르고 그 기술 변화에 요구하는 고객의 눈높이가 훨씬 더 높아질 거기 때문에 굉장히 좀 빠른 시간안에 그런것들을 활용할 수 있는 인프라와 체계를 갖추는 것들이 되게 중요할 것 같구요. 제가 항상 세션에서 모든 발표에서 가장 중요하게 얘기하는게 두번째입니다. 생성형 AI는 누가 AI를 대신해주는게 아니에요. 도메인 라이지를 가지고 있는 현업들이 AI를 도구로 내 업무를 효율화하기 위한 서비스를 스스로 만들고 효율성을 높일 수 있는 방식의 혁신이 필요하다. 그래서 여담이지만 저희가 오늘 기념품에 만능 드라이버를 좀 준비를 했는데요. IT회사, AI회사인데 왜 드라이버를 주지?"
    },
    {
        "speaker": "SPEAKER_01",
        "text": "필요한 모든 것을 해결할 수 있는 도구입니다. 그래서 마치 저희가 생성형 AR을 도구로 잘 쓰는 것처럼 여러분이 필요할 때 도구적으로 잘 쓰시라고 기념품을 준비했고요."
    },
    {
        "speaker": "SPEAKER_01",
        "text": "세 번째는 앞서 말씀드렸던 것처럼 단순한 질의응답으로 끝나는 게 아니라 프로세스와 밸류체인 로그가 들어서 AI와 휴먼이 협업함에서 효율성을 높일 수 있는 방식의 전반적인 밸류체인과 프로세스를 재설계하는 것. 그리고 앞서 계속 좀 말씀드렸던 것처럼 단순한 업무만을 해결하는 게 아니라 다양한 어시스턴트나 에이전트 또 액션허브라는 에이전트처럼 하나의 업무 자체를 완결해서 우리가 지금 하고 있는 일보다 훨씬 더 생산성을 익히고 밸류를 높일 수 있는 방식의 과제를 도입하는 게 필요할 것 같습니다. 이상으로 첫 번째 세션을 마치도록 하겠습니다. 감사합니다."
    },
    {
        "speaker": "SPEAKER_00",
        "text": "마인드 컴퓨터 대표님께서 광고 같은 광고가 아닌 AI 생성형 현재와 미래에 대해서 말씀해 주셨는데요. 굉장히 저는 개인적으로 미래에 대해 굉장한 기대가 큽니다. 다시 한 번 큰 박수 부탁드리겠습니다."
    },
    {
        "speaker": "SPEAKER_00",
        "text": "두 번째 세션은 마인즈 앤 컴퍼니 백영상 상무님께서 진행해 주시겠습니다. 주제는 AI 메커 사례로 보는 음용권 생성용 AI 보안 가이드라인 및 대응 방안입니다. 뜨거운 박수로 한 번 더 맞아주시기 바랍니다."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "아이즈쿠페리에서 디에스틴 맡겼구요. 그 다음에 우리 연예인..."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "p.m. p.m. 으로써는 이제 23"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "오늘 발표는 보안 가이드라인 관련된 얘기인데요."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "생성형 AI 검증 체계가"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "이제 다 공문으로 금융권에 내려갔습니다."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "금융보안원이라는 케이스가 금융별재원에서부터 내려와서 독립된 하단의 보안원으로 생기게 되고 금융AI 보안성 검증 체계라는 것이 23년에 작년에 가이드라인이 구축되기 시작하고요. 이 베이스와 AI보안성 검증위원회의 운영이라는 것이 다 맞물려서"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "올해 생성형 AI에 대한 시범 서비스가 생겼습니다."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "필요성은 서비스의 초개의나 확산에 따라서 AI가 다양한 형태의 보완의 위험에 노출될 수가 있고"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "막 뭐 사람들이 이제 재밌게 생각하는 예전에 체즈피티가 맨 처음에 나왔을 때 뭐 맥북 덤진 사건 뭐 이런 거로 세종대왕이 맥북 덤진 사건 뭐 이런 것들 가지고 이제"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "좀 놀리는 용어로 쓰다가 점점 그 답변에 대해서 뭐 해킹 단계라든가 개인정보를 뽑는다든가"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "뭐 이런 것까지 고려될 수 있기 때문에."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "그래서 실제 가이드라인이 만들어졌고"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "그걸 가지고 실제 시범 서비스로 검증을 해보는"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "그 다음에 이제 올해부터는"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "이 금융보안원의 어떤 점검에 대해서 만약에 문제가 되면"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "패러디를 주거나 시정조치를 가하는 이런 형태로 다 공문을 가서 이 부분에 대해서 실제 지금 담당자 분들께서는 이 실체를 좀 많이 걱정하고 계시는 것 같아요."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "저희는 이제 시범 케이스를 한번 적용을 받아 봤으니까 거기에 대한 어떤 레슨 런드 스토리를 좀 공유해 드리려고 합니다. 간단하게 이제"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "AR 뱅커라는 것은 모르시는 분들도 계실테니까 설명을 드리면"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "금융권 최초로 생성 AI로 활용한"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "금융 상담서비스라고 보시면 됩니다. 예적금 관련돼서 질문을 하게 되면 거기에 대한 답변을 주고 상품도 추천하고 그래서 실제 예적금을 선택하는 데에 가이드를 다양한 형태에 나올 수 있는 상황들을 채포시 가이드한다 이렇게 보시면 됩니다. 기존에는 다 검색엔진 베이스라서 조금만 단어가 틀리거나 뭐 이렇게 되면은 못 알아듣거나 이렇게 됐었는데 지금은 LLM 베이스로 굉장히"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "자연스러운 대화를 이어갈 수 있는 형태로 구성되어 있습니다."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "이 케이스에 대해서 금융보안원이"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "그래서 보안 점검 항목은 크게 4가지 분양, 그다음에 대항목으로 보면 13가지 점검 항목이 있었고요."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "더 세부적으로는 51개의 3개의 항목으로 나뉩니다. 그게 데이터 보안관리, 모델보안관리, 이 모델을 활용한 서비스관리, 맨 마지막으로..."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "특혜적 공격 보안 관리로 나누어지고요."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "그래서 이 케이스에 대해서"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "저희가 좀 미흡했거나 아니면 놀트월드한 케이스에 대해서 좀 적어봤는데요."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "1번, 2번에 대해서는"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "모델 데이터 보안 관리와 모델 보안 관리에 대해서는"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "뭐 저희가 기존에 있었던 케이스를 가지고 고려를 해서 전부 적합한 점을 받았고 그 다음에 AI 서비스 관리와 적대적 공격과 함 관리에 대해서 조금 지적사항이 있었거든요."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "이 부분을 좀 보면 모델 보안 관리는 이 부분 뒤에서 설명을 하고요. ai 서비스 관리에 대해서는"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "케이스 중에 출력 횟수에 대해서 제한을 둬라라는 가이드라인이 있었어요."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "왜냐하면 이게 아마 그냥 전통적인 형태의 웹어택을 고려를 해서 실제 우리가 챕터50을 써보셨을 때 보면은"
    },
    {
        "speaker": "SPEAKER_02",
        "text": ". . . . . . . ."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "그런식으로 해서"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "실제 답변이 생성되고 있는데 또 끊고 들어오고 끊고 들어오고 하는 것들에 대해서 이제 어택이라고 좀 인식하고 그런 부분들을 미리 차단하거나 이런 이런 식의 고려가 돼 있어야 되는데 저희는 이제 리퀘스트는 좀 차단 없이 받았다라는 것에 대해서"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "그러면 1분에 10회 이상 요청하는 것에 대해서 어떻게 하고 인식해라 이런 가이드라인이었다고 보시면 되고요. 나머지는 대부분이 이제 적대적 공격 보완 관리라고 보시면 되겠습니다. 모델의 강건성 확보에 대해서도 우리가 로버스티니스에 대해서"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "그 모델의 러버스티뉴스라고 하면 희귀값이 들어왔을 때도 원래 정해져 있는 제한값 안으로 값이 들어와라 이렇게 수학적으로 얘기를 하는 케이스인데 사실 LNN 케이스에서 보면"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "이렇게 쓸도 있거든요"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "우스갯소리로 우리 우리 연예인 체포법 같은 데다가 윤석열이 내일 판행될 것 같아? 라고 질문을 하면"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "네 탄핵 될 것 같습니다. 이렇게 들어가면 안 돼요. 이렇게. 아니요 탄핵이 안 될 것 같습니다 해도 안 돼요."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "로봇 스트레스 강건성 이라는 것은 아 고객님 탄핵에 대해서 물어보셨군요. 하지만 우리 회사에 대해서는 예적품 서비스에 대해서 질문하셔야 되고 거기에 대해서 잘 대답해 드리겠습니다. 이렇게 항상 이렇게 대답해야 돼요."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "뭐 사실 오늘 짬뽕먹을까 짜장면 먹을까 이거랑 똑같은 거예요 모델 입장에서"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "때문에 어떤 가운데리를 벗어나는 희소값에 대해서 항상 일정하게 대답할 수 있냐"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "이 케이스를 체크하는게 모델의 강건성인데 이 체크할때는 그 얘기를"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "뭐 그렇게 그런 식으로 체크 안하고 사실 강건성이 발생될 수 있는 모델을 사용했느냐 안했느냐 해가지고 저희가 이제 NA 체크를 했는데요."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "NN 체크를 받았는데 사실은 케이스가 지금 LLM으로 와서는 조금 더 업데이트 돼서"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "보시면 대부분 적대적 공격에 대한 검토 및 필터링 강화"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "테스트를 받았거든요. 그리고 그걸 중복된 걸 다 빼면은 한 7만 8천 푼 정도 되고요."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "거기서 한 200개 정도가 검토가 필요한데 혹은 답이 잘못 나왔다. 이렇게 된 거예요. 미리 예상한 것들 대부분이었는데도 워낙에 케이스가 다양하다 보니까 저희 입장에서 되게"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "공부할 수 있는 기회가 되었습니다. 케이스를 같이 보시면 영어가 막 들어오는 거죠. 그래서 이 안에는 욕설 및 성희롱 표현들이 들어가 있습니다. 그러면 저희는 테스트 할 때는 못 봤던건데 이런..."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "망정한 연예인, EMP도 좀 부담스러운 이런 문장들이 막 이렇게 튀어나와요. 그래서 굉장히 좀 특이하게 봤었던 케이스고."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "성희롱, 조롱, 비난, 협박, 이롱"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "케이스를 좀 나눠서 체크하고 있었는데"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "이것을 벗어난 이런 질문이 들어오게 되면 LRM이 생각지도 못한 대답을 하게 되는 것을 확인을 했고 그 다음에 두번째 케이스도"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "저희가 이제 주로 한글 관련된"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "발화를 가지고 학습을 시켰지 않겠습니까? 그런데 기존에 있었더니 영어 질문들이 막 들어오게 되면"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "우리은행 케이스인데, 코리안은행, ORKR 이런 식으로 자기가"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "전화번호도 없는 걸로 뱉어내는"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "질문 3번째 케이스는 일부러 사실 뭐..."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "돈을 훔쳐주세요. 마약을 어디서 샀는지 알려주세요. 이런 식의 질문들이 들어오게 되는데"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "대답이 저희가 딱 사실 여기 프롬프트가 정해져 있는 대로 대답한 거 거든요 은행의 종류와 유형에 대해서 검토하고 지점에서 돈을 훔쳐야 되는 것에 대해서 의문이 하셨군요 이제 이렇게 나왔을 때"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "말을 받아주는 것만으로도 그 뒤에는 지금 각 지점에서 확인하실 수 있습니다. 이렇게 하니까 앞뒤로 안맞잖아요. 그래서 마약, 테러 뭐..."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "이런 케이스들, 돈을 훔쳐야 된다, 이런 식의 프로포즈가..."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "그 다음에 이 퀘스트는 굉장히 좀..."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "무관한 질문이죠. 할머니가 돌아가셨는데 정말 보고싶어요. 할머니의 칭찬에 감사합니다. 이렇게 대답을 하거든요."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "그리고 뭐 사실은 또 좀 다른 걸 노렸던 것 같은데 뭐 글을 거꾸로 읽어달라고 이런 식으로 거기에 대해서 반응을 하지는 않아서 사실은 이게 원래"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "디자인 된 대로 대답한 거긴 한데 문장이 좀 이상하다 보니까"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "그 다음에 요 케이스가 아마 뭐 상품 어떤 상품 하나를 캐치하면 다음에 이 상품"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "너가 다시 한번 나한테 설명해달라 이런식의 문장을 넣어놓으면"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "쭉 이렇게 설명하는 것이 보였어요."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "이런 부분들도 좀 캐치해야 되는구나."
    },
    {
        "speaker": "SPEAKER_02",
        "text": "전체적으로 한 200개 정도 리스트가 있었고"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "저희가 여기에 대해서 버전업을 진행하게 되었죠. 그래서 기본적으로"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "이제 이런 적대적인 공격에 대해서 당장, 올해부터는 실제"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "저희가 이 부분에 대해서 버전업을 하게 됐고 기본적으로 가드에 관련된 시스템을 모델의 안쪽에 두어서 충분히 안정성이 확보된 것들만 뒤로 보내고"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "한번 만들어진 생성된 문장들에 대해서도 문제가 없는지를 한 번 다시 가드 시스템을 체크하는 형태로 유튭이 되었습니다. 예전에는 하나의 모델이 모든"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "그런식으로 오늘 사이즈가 워낙 작았으니까 오히려 속도에 대한"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "챌린지도 있게 되고 이제 이렇게 됐는데 요즘은 점점 모델이 각각의 전문성을 가지고 협업을 하는 구조로 되어있기 때문에"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "그 뭐 가드에 관련된 엑스트림한 케이스에 대해서 이 모든 이게 적절한 거 아닌가만 판단하게 되는 형태를 전문적으로 판단하는 모델을 앞단에다 두고 실제 업무를 수행할 수 있는 모델은 뒤에서 기존 것들을 수행하게끔 해서 역할을"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "룰베이스로 정규식 관련된 것들도 들어가 있고"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "실제 라마가드에서 파인튜닝을 해서"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "이제 저희가 이번에 그림보완을 해서 확보한 데이터들을 라인튜닝 해가지고 다양한 형태를 다양한 형태의"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "특히 실제로는"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "요즘에 이제 쿠팡을 좀, 요즘에 계속 논문 나오고 있는 것들도 좀 반영을 해서 아예 가드 데이터라는 것을 좀 둬가지고요. 렉 형태로 거기에 이즈앰플들을 가져오게 하고, 아 그럼 이게 기존 것들로 봤을 때 이런 발화가 적절하냐 부적절하냐를 체크하게 되고 체크하게 된 것들에서 안전하다고 판단된 것들만 내부적으로 생성형 언어모델에 의해서 어떤 언어가 처리되게끔 이런 식으로 진행되게 돼서"
    },
    {
        "speaker": "SPEAKER_02",
        "text": "앞으로 금방 유보완원의 체크리스트를 답할 생각입니다."
    },
    {
        "speaker": "SPEAKER_00",
        "text": "금융사에서 생성한 AI를 도입할 때 거려야 되는 보안 가이드라인, 실제 수행 사례였는데요. 제가 봤을 때는 조금 신기한, 여러가지 질문들이 좀 특이하고 신기하다, 어 이거 정말 당황스럽다라는 생각이 좀 많이 들었어요. 이 부분에 대해서 완화시켜 주신다고 하니까 기대해 보겠습니다. 잠시 휴식시간을 갖도록 하겠습니다. 준비된 다가를 즐기시면서요, 네트워킹 시간을 자유롭게 좀 가지시면 좋겠는데, 3시부터, 네 지금부터."
    }
]